---
title: "Religion vs corruption dataset"
author: "Marina Ramírez Baños, Giovanni Vincenzo Cavallo, Pablo Bondia Portoles, Priyanka"
date: "2024-11-05"
output: html_document
---

# Import data

First, let's load the packages needed and import both datasets.

```{r}
# Load tidyverse and readr packages

library(tidyverse)
library(readr)

# Import religion_by_country and corruption_by_country datasets

religion_by_country <- read_csv("religion-by-country-2024.csv")

corruption_by_country <- read_delim("CPI2020_for_merge.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

```

Second, we are going to filter the "religion_by_country" dataset to include only the data from 2020.


```{r}
# We have missing data for 2020 for United State, so we are gonna use the data from 2010 as an alternative

religion_by_country[religion_by_country$country == "United States", c("ReligionByCountry_TotalReligious_2020",  "religionByCountry_christians_2020", 
"religionByCountry_muslims_2020", "religionByCountry_hindus_2020", 
"religionByCountry_buddhists_2020", "religionByCountry_folkReligions_2020", 
"religionByCountry_jews_2020", "religionByCountry_other_2020", 
"religionByCountry_unaffiliated_2020")] <- religion_by_country[religion_by_country$country == "United States", c("total", "religionByCountry_christians", 
"religionByCountry_muslims", "religionByCountry_hindus", 
"religionByCountry_buddhists", "religionByCountry_folkReligions", 
"religionByCountry_jews", "religionByCountry_other", 
"religionByCountry_unaffiliated")]

#This piece of code copies the data for United States from 2010 into 2020 columns
```


```{r}

dput(names(religion_by_country))


# Filter religion_by_country dataset only including the data from 2020

religion_by_country <- religion_by_country %>% select("country", "ReligionByCountry_TotalReligious_2020",  "religionByCountry_christians_2020", 
"religionByCountry_muslims_2020", "religionByCountry_hindus_2020", 
"religionByCountry_buddhists_2020", "religionByCountry_folkReligions_2020", 
"religionByCountry_jews_2020", "religionByCountry_other_2020", 
"religionByCountry_unaffiliated_2020")



```

We are going to create a dataset percentage_religion_by_country that includes the percentage of people of each religion over the total population of the country.

```{r}
# Create new columns

#Total population
percentage_religion_by_country <- religion_by_country %>% mutate(
  total_population = ReligionByCountry_TotalReligious_2020 + religionByCountry_unaffiliated_2020
)

#Proportion of individuals from each religion
percentage_religion_by_country <- percentage_religion_by_country %>% mutate(
  percentage_ReligionByCountry_TotalReligious_2020 = ((ReligionByCountry_TotalReligious_2020
)/total_population)*100,
  percentage_religionByCountry_christians_2020 = ((religionByCountry_christians_2020
)/total_population)*100,
percentage_religionByCountry_muslims_2020 =((religionByCountry_muslims_2020
)/total_population)*100,
percentage_religionByCountry_hindus_2020 = ((religionByCountry_hindus_2020
)/total_population)*100,
percetage_religionByCountry_buddhists_2020 = ((religionByCountry_buddhists_2020
)/total_population)*100,
percentage_religionByCountry_folkReligions_2020 = ((religionByCountry_folkReligions_2020
)/total_population)*100,
percentage_religionByCountry_jews_2020 = ((religionByCountry_jews_2020
)/total_population)*100,
percentage_religionByCountry_other_2020 = ((religionByCountry_other_2020
)/total_population)*100,
percentage_religionByCountry_unaffiliated_2020 = ((religionByCountry_unaffiliated_2020
)/total_population)*100
)

# Remove the other columns that do not include the proportions of individuals
percentage_religion_by_country <- percentage_religion_by_country %>% select(-starts_with("religion", ignore.case = TRUE))

```

# Merging datasets

To merge both datasets we have to use a variable they have in common. In our case, that variable is "country". However, we firstly need to rename "Country" in the corruption_by_country dataset to "country", as it is in the percentage_religion_by_country dataset.

```{r}
# Rename "Country" to "country" from corruption_by_country dataset

corruption_by_country <- corruption_by_country %>% rename(country = Country)

# Use full_join() from tidyverse to merge the datasets by country. By doing that, if a country is included in the dataset 1 but not in dataset 2, the columms of dataset 2 will contain "NA" values for that rows and viceversa

merged_dataset <- full_join(percentage_religion_by_country, corruption_by_country, by = "country")

```

# Tidying data

For the purpose of the analysis, we want to exclude those countries that do not show data about the amount of religious population in 2020 or have a NA value for CPI score 2020.


```{r}
# Remove from merged_dataset those countries with NA values for total_population

merged_dataset <- merged_dataset %>% filter(!is.na(total_population))

# Remove from merged_dataset those countries with NA values for CPI score 2020

merged_dataset <- merged_dataset %>% filter(!is.na(`CPI score 2020`))

```


Before performing the correlation analysis we check assumptions:

1. Linearity check: Pearson’s correlation measures only linear relationships. If the relationship is non-linear (e.g., quadratic or logarithmic), Pearson’s correlation may underestimate or misrepresent the true relationship.

2. 1.3. Homoscedasticity (Equal Variances):  If the variability of one variable increases as the other variable increases (called heteroscedasticity), Pearson’s correlation may not be valid, leading to incorrect conclusions about the strength of the relationship.



```{r}
# Load ggplot2 library
library(ggplot2)

# Example: Scatterplot to check linearity
ggplot(merged_dataset, aes(x = percentage_religionByCountry_unaffiliated_2020, y = `CPI score 2020`)) +
  geom_point() +                          # Plot the data points
  geom_smooth(method = "lm", se = FALSE, col = "red") +  # Add a linear regression line
  labs(title = "Scatterplot: Corruption vs % Unaffiliated",
       x = "% of affiliation", y = "% CPI") +
  theme_minimal()


```
## COMENT THE PLOT ADOVE


2. Normality of variables: Pearson’s correlation assumes that the data comes from normal distributions, so violations of normality can affect the p-value and the confidence interval of the correlation coefficient, making the test less reliable. 

If it is not normal we would still do the analysis as the sample size (number of countries) is quite large so under the CLT we can make the anlaysis.

## ERROR WHEN MAKING HISTOGRAM FOR CPI SCORE 2020 + Q Q CPI SCORE 2020 -> NOT CONINUOUS

```{r}
# Histogram for each variable

# Apply log transformation
merged_dataset$NonReligious_Log <- log(merged_dataset$percentage_religionByCountry_unaffiliated_2020)

# Check histogram for CPI score 2020
# ggplot(merged_dataset, aes(x = `CPI score 2020`)) + 
#   geom_histogram(bins = 20, fill = "lightblue", color = "black") +
#   labs(title = "Histogram of Corruption Index")

# Check histogram for original non-religious percentage
ggplot(merged_dataset, aes(x = NonReligious_Log)) + 
  geom_histogram(bins = 20, fill = "lightblue", color = "black") +
  labs(title = "Histogram of Non-Religious Percentage")

# Q-Q plot for CPI score 2020
# qqnorm(merged_dataset$`CPI score 2020`)
# qqline(merged_dataset$`CPI score 2020`, col = "red")

# Q-Q plot for original non-religious percentage
qqnorm(merged_dataset$NonReligious_Log)
qqline(merged_dataset$NonReligious_Log, col = "red")



```
After log transformation, the obtained histogram for non-religious population seemed nornally distributeb. Few outliers were observed, but since they represent relevant cases we decide to keep them and assume a normally distributed data.



## I CAN'T GET THIS: After log10 the CPI, we get a more normal like histogram although a bit skewed.

3. Homoscedasticity (Equal Variances):  If the variability of one variable increases as the other variable increases (called heteroscedasticity), Pearson’s correlation may not be valid, leading to incorrect conclusions about the strength of the relationship.
Another Check for Homoscedasticity 
```{r}

model <- lm(`CPI score 2020` ~ `NonReligious_Log`, data = merged_dataset)
plot(model$residuals ~ model$fitted.values)
abline(h = 0, col = "red")

```
The obtained plot is Fan-shaped, which indicates heteroscedasticity. Then, it it would break homoscedasticity assumption.
## I DONT UNDERSTAND THIS: No problem for correlation but it is a problem for regression.


4. Check for outliers:

```{r}
# Boxplot to check for outliers in 'percentage_religionByCountry_unaffiliated_2020'
boxplot(merged_dataset$NonReligious_Log,
        main = "Boxplot for Non-Religious Percentage",
        ylab = "Non-Religious Percentage",
        col = "lightblue")

```

As observed in the histrogram, we got few outliers. To further assess outliers we perform a leverage analysis:

To evaluate the influence of this outliers I will utilize Leverage and Cook's tests

Leverage measures how far an observation’s predictor values are from the mean of the predictor variables. High-leverage points CAN disproportionately influence the regression line, especially if they are outliers in the outcome variable as well.

```{r}

leverage <- hatvalues(model)
plot(leverage, main = "Leverage Values")
abline(h = 2*(length(coef(model))/nrow(merged_dataset)), col = "red")  # Threshold line

summary(leverage)

```

The leverage analysis show that 9 points have the potential of being influential.

To further examine this points we will use cooks test:

```{r}

# Calculate Cook's Distance
cooksD <- cooks.distance(model)

# Plot Cook's Distance
plot(cooksD, main = "Cook's Distance", pch = 19, col = "blue")
abline(h = 4/length(cooksD), col = "red")  # Reference line for Cook's Distance at 4/n

# Identify influential observations
influential_points <- which(cooksD > 4/length(cooksD))
cat("The influential observations are: ", influential_points, "\n")

influential_data <- merged_dataset[influential_points, ]
print("Influential data:")
print(influential_data)


```
From this plot we see that there are 7 points that are truly highly influential on the model (over the threshold), and since they are significant valid data-points, and not measurements mistakes it would not be correct to eliminate them from the analysis.

Also, we re-evaluated the Model Fit by removing or adjusting influential points temporarily to assess their impact on the regression coefficients and see if they distort the mode and it didn't change that much:
```{r}
# Create side-by-side plots
par(mfrow = c(1, 2))  # Set up for two plots

# Model with all data
plot(merged_dataset$NonReligious_Log, merged_dataset$`CPI score 2020`, 
     main = "Model with All Data", 
     xlab = "NonReligious_Log", ylab = "CPI score 2020", pch = 19, col = "blue")
abline(model, col = "red")

# Model without influential observations
plot(merged_dataset$NonReligious_Log, merged_dataset$`CPI score 2020`, 
     main = "Model without Influential Points", 
     xlab = "NonReligious_Log", ylab = "CPI score 2020", pch = 19, col = "black")
abline(model_without_influential, col = "green")
```


```{r}

# Create the model with all data
model <- lm(`CPI score 2020` ~ `NonReligious_Log`, data = merged_dataset)

# Create the model without the influential points
model_without_influential <- lm(`CPI score 2020` ~ `NonReligious_Log`, 
                                data = merged_dataset[-influential_points, ])

# Print the coefficients for the model with all data
coef_all_data <- coef(model)
cat("Coefficients for the model with all data:\n")
print(coef_all_data)

# Print the coefficients for the model without influential observations
coef_without_influential <- coef(model_without_influential)
cat("\nCoefficients for the model without influential points:\n")
print(coef_without_influential)


```

The tests carried out are enough to determine that parametric tests should not be utilized with this data, therefore, both for correlation and regression, non-parametric tests should be used.
